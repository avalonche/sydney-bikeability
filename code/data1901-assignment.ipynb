{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New dataset via webscrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"http://crimetool.bocsar.nsw.gov.au/bocsar/\")\n",
    "web_content = BeautifulSoup(page.content, 'html.parser')\n",
    "suburbid = OrderedDict()\n",
    "suburbs = web_content.find(class_=\"ribbon-input search-content\").find_all(\"option\")[1:]\n",
    "for suburb in suburbs:\n",
    "    attrs = suburb.attrs\n",
    "    if attrs[\"title\"] == \"2\":\n",
    "        suburbid[attrs[\"value\"]] = suburb.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 658 suburbs in Sydney, list of names obtained from Wikipedia, filtering out the suburb ids\n",
    "sydney_suburb_list = []\n",
    "suburb_url = requests.get(\"https://en.wikipedia.org/wiki/List_of_Sydney_suburbs\")\n",
    "sydney_suburb = BeautifulSoup(suburb_url.content, 'html.parser')\n",
    "sydney_suburb = sydney_suburb.find_all(\"p\")\n",
    "for suburb in sydney_suburb:\n",
    "    suburbs = suburb.find_all(\"a\")\n",
    "    for  i in range(len(suburbs)):\n",
    "        if \"title\" in suburbs[i].attrs.keys():\n",
    "            if suburbs[i][\"title\"].endswith(\", New South Wales\"):\n",
    "                name = suburbs[i][\"title\"].split(\",\")[0]\n",
    "                # cleaning up the data for name differences \n",
    "                if name == u'Bankstown Airport':\n",
    "                    name = u'Bankstown Aerodrome'\n",
    "                sydney_suburb_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some suburbs are in the wiki list but not the suburbid, some suburbs have the same name, need to get rid of that\n",
    "# 654 + 16 (duplicates) = 670\n",
    "sydney = OrderedDict()\n",
    "for i in range(len(sydney_suburb_list)):\n",
    "    for k, v in suburbid.items():\n",
    "        v = v.replace(\"(Suburb)\",\"\")\n",
    "        if v.startswith(sydney_suburb_list[i].upper()):\n",
    "            sydney[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting offenceids\n",
    "offenceid = OrderedDict()\n",
    "offences = web_content.find(class_=\"offence_list\").find(\"nav:group\")\n",
    "while offences != None:\n",
    "    attrs = offences.attrs\n",
    "    if attrs[\"datavalue\"] == \"\" and attrs[\"title\"] == \"More Offences\":\n",
    "        other = offences.find(\"nav:item\")\n",
    "        while other!= None:\n",
    "            offenceid[other[\"datavalue\"]] = other[\"title\"]\n",
    "            other = other.find_next(\"nav:item\")\n",
    "    if attrs[\"datavalue\"] != \"\":\n",
    "        offenceid[\"-\"+attrs[\"datavalue\"]] = attrs[\"title\"]\n",
    "    offences = offences.find_next(\"nav:group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import pprint\n",
    "import random\n",
    "import time \n",
    "base_url =  \"http://crimetool.bocsar.nsw.gov.au/bocsar/api/\"\n",
    "stats = \"TableDataQuick\"\n",
    "regionids = [x for x in sydney.keys()]\n",
    "crimelist= []\n",
    "# url length limit is 500, otherwise would throw a 414 error, we split the query two parts\n",
    "def apiCall(start, finish):\n",
    "    flag = 0\n",
    "    for offence in offenceid.keys():\n",
    "        statparams = {\"RegionId\":regionids[start:finish],\"RegionTypeId\":2,\"Start_Year\":2017,\"End_Year\":2018,\"Month\":12,\"DataType\":\"I\",\\\n",
    "    \"OffenceId\":offence}\n",
    "        response = requests.get(base_url + stats, params = statparams)\n",
    "        results = response.json()\n",
    "        data = results[\"data\"]\n",
    "        if flag == 0:\n",
    "            for i in range(len(data)):\n",
    "                flag = 1\n",
    "                crime = {\"2018_count\":data[i][\"2018_count\"],\"2018_pop\":data[i][\"2018_pop\"],\\\n",
    "                            \"RegionId\":data[i][\"REGIONID\"], \"name\":data[i][\"NAME\"]}\n",
    "                crimelist.append(crime)\n",
    "        elif flag == 1:\n",
    "            for i in range(len(data)):\n",
    "                crimelist[start+i][\"2018_count\"] += data[i][\"2018_count\"]\n",
    "        sleeptime = random.randint(1,5)\n",
    "        time.sleep(sleeptime)\n",
    "apiCall(0,500)\n",
    "apiCall(500,len(regionids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to append the geometry data and store in geojson \n",
    "# note that in the API call, results[\"data\"][0] is for the whole of New South Wales\n",
    "# as we split and repeated the work twice, need to delete entry 501\n",
    "del crimelist[501]\n",
    "crimefeatures = []\n",
    "for i in range(len(regionids)):\n",
    "    insert = crimelist[i+1]\n",
    "    url = base_url + \"Geometry/\" + regionids[i]\n",
    "    geo = requests.get(url)\n",
    "    geoda]ta = geo.json()[\"geometry\"]\n",
    "    feature = geojson.Feature(properties={\"2018_count\":insert[\"2018_count\"], \\\n",
    "                                                                    \"2018_pop\":insert[\"2018_pop\"], \\\n",
    "                                                                    \"RegionId\":insert[\"RegionId\"], \\\n",
    "                                                                    \"name\":insert[\"name\"] \\\n",
    "                                                                    })\n",
    "    feature[\"geometry\"] = geodata\n",
    "    crimefeatures.append(feature)\n",
    "    time.sleep(random.randint(1,5))\n",
    "crime_collection = geojson.FeatureCollection(crimefeatures) \n",
    "with open('crimefeatures.geojson', 'w') as f:\n",
    "   geojson.dump(crime_collection, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SA2 shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapefile\n",
    "sf = shapefile.Reader(\"SA2/SA2_2016_AUST.shp\", encoding=\"iso-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "def pgconnect():\n",
    "    try: \n",
    "        conn = psycopg2.connect(host='',\n",
    "                                database='',\n",
    "                                user='',\n",
    "                                password=YOUR_PW) \n",
    "        print('connected')\n",
    "    except Exception as e:\n",
    "        print(\"unable to connect to the database\")\n",
    "        print(e)\n",
    "    return conn\n",
    "\n",
    "conn = pgconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgquery( conn, sqlcmd, args=None, msg=False, returntype='tuple'):\n",
    "    retval = None\n",
    "    with conn:\n",
    "        cursortype = None if returntype != 'dict' else psycopg2.extras.RealDictCursor\n",
    "        with conn.cursor(cursor_factory=cursortype) as cur:\n",
    "            try:\n",
    "                if args is None:\n",
    "                    cur.execute(sqlcmd)\n",
    "                else:\n",
    "                    cur.execute(sqlcmd, args)\n",
    "                if (cur.description != None ):\n",
    "                    retval = cur.fetchall() # we use fetchall() as we expect only _small_ query results\n",
    "                if msg != False:\n",
    "                    print(\"success: \" + msg)\n",
    "            except psycopg2.DatabaseError as e:\n",
    "                if e.pgcode != None and msg:\n",
    "                    print(\"db read error: \"+msg)\n",
    "                    print(e)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aust_schema = '''CREATE TABLE AUST (\n",
    "                     SA2_MAIN16 INTEGER, \n",
    "                     SA2_5DIG16 INTEGER, \n",
    "                     SA2_NAME16 VARCHAR(80), \n",
    "                     SA3_CODE16 INTEGER,\n",
    "                     SA3_NAME16 VARCHAR(80),\n",
    "                     SA4_CODE16 INTEGER,\n",
    "                     SA4_NAME16 VARCHAR(80),\n",
    "                     GCC_CODE16 VARCHAR(80),\n",
    "                     GCC_NAME16 VARCHAR(80),\n",
    "                     STE_CODE16 INTEGER,\n",
    "                     STE_NAME16 VARCHAR(80),\n",
    "                     AREASQKM16 INTEGER,\n",
    "                     geom GEOMETRY(Polygon,4326),\n",
    "                     CONSTRAINT aust_area_id_fkey FOREIGN KEY (SA2_MAIN16)\n",
    "                     REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)''' \n",
    "\n",
    "pgquery(conn, \"DROP TABLE AUST\",msg=\"cleared old table\")\n",
    "pgquery(conn, aust_schema, msg=\"created AUST table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO AUST VALUES ( %(SA2_MAIN16)s, %(SA2_5DIG16)s, %(SA2_NAME16)s, %(SA3_CODE16)s, %(SA3_NAME16)s,\n",
    "                                            %(SA4_CODE16)s, %(SA4_NAME16)s,%(GCC_CODE16)s,%(GCC_NAME16)s,%(STE_CODE16)s,\n",
    "                                            %(STE_NAME16)s,%(AREASQKM16)s,\n",
    "                                            ST_GEOMFROMTEXT(%(geom)s, 4326) )\"\"\"\n",
    "\n",
    "shapes = sf.shapes()\n",
    "records= sf.records()\n",
    "\n",
    "row = {}\n",
    "for i in range(0, len(shapes)):\n",
    "    record = sf.record(i)\n",
    "    shape  = sf.shape(i)\n",
    "    row['SA2_MAIN16']=record[0]\n",
    "    row['SA2_5DIG16']=record[1]\n",
    "    row['SA2_NAME16']=record[2]\n",
    "    row['SA3_CODE16']=record[3]\n",
    "    row['SA3_NAME16']=record[4]\n",
    "    row['SA4_CODE16']=record[5]\n",
    "    row['SA4_NAME16']=record[6]\n",
    "    row['GCC_CODE16']=record[7]\n",
    "    row['GCC_NAME16']=record[8]\n",
    "    row['STE_CODE16']=record[9]\n",
    "    row['STE_NAME16']=record[10]\n",
    "    row['AREASQKM16']=record[11]    \n",
    "    row['geom']=\"POLYGON((\"\n",
    "    i=0\n",
    "    for x, y in shape.points:\n",
    "       row['geom']+=\"%s %s,\" % (x,y)\n",
    "       # check for start of a new polygon part\n",
    "       i += 1\n",
    "       if i in shape.parts:\n",
    "           row['geom']= re.sub(\",$\", \"),(\", row['geom'])\n",
    "    # properly end the polygon string\n",
    "    row['geom'] = re.sub(\",$\", \"))\", row['geom'])\n",
    "    # finally: insert new row into the table\n",
    "    if row['GCC_NAME16']=='Greater Sydney':pgquery(conn, insert_stmt, args=row, msg=\"inserted \"+str(record[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv and scrapped data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load five files\n",
    "import csv\n",
    "import pandas as pd\n",
    "data_bikesharingpods=list(csv.DictReader(open('data/BikeSharingPods.csv')))\n",
    "data_businessstats=list(csv.DictReader(open('data/BusinessStats.csv')))\n",
    "data_censusstats=list(csv.DictReader(open('data/CensusStats.csv')))\n",
    "data_neighbourhoods=list(csv.DictReader(open('data/Neighbourhoods.csv')))\n",
    "data_statisticalareas=list(csv.DictReader(open('data/StatisticalAreas.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_businessstats1=pd.read_csv('data/BusinessStats.csv')\n",
    "business_mean={}\n",
    "for i in data_businessstats1:\n",
    "    business_mean[i]=int(data_businessstats1[i].mean()+0.5)\n",
    "    \n",
    "data_censusstats1=pd.read_csv('data/CensusStats.csv')\n",
    "censuss_mean={}\n",
    "for i in data_censusstats1:\n",
    "    censuss_mean[i]=int(data_censusstats1[i].mean()+0.5)\n",
    "\n",
    "data_neighbourhoods1=pd.read_csv('data//Neighbourhoods.csv')\n",
    "neighbourhoods_mean={}\n",
    "for i in data_neighbourhoods1:\n",
    "    if i!='area_name':neighbourhoods_mean[i]=int(data_neighbourhoods1[i].mean()+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statisticalareas_schema=''' CREATE TABLE IF NOT EXISTS statisticalareas(\n",
    "                        area_id integer NOT NULL,\n",
    "                        area_name varchar(80),\n",
    "                        parent_area_id integer,\n",
    "                        CONSTRAINT statisticalareas_pkey PRIMARY KEY (area_id))'''\n",
    "\n",
    "\n",
    "pgquery(conn, \"DROP TABLE statisticalareas\",msg=\"cleared old table\")\n",
    "pgquery(conn, statisticalareas_schema, msg=\"created statisticalareastable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO statisticalareas(area_id,area_name,parent_area_id) VALUES (%(area_id)s, %(area_name)s, %(parent_area_id)s)\"\"\"\n",
    "for row in data_statisticalareas:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessstats_schema=''' CREATE TABLE IF NOT EXISTS businessstats(\n",
    "                            area_id integer NOT NULL,\n",
    "                            num_businesses integer,\n",
    "                            retail_trade integer,\n",
    "                            accommodation_and_food_services integer,\n",
    "                            health_care_and_social_assistance integer,\n",
    "                            education_and_training integer,\n",
    "                            arts_and_recreation_services integer,\n",
    "                            CONSTRAINT bussinessstats_pkey PRIMARY KEY (area_id),\n",
    "                            CONSTRAINT bussinessstats_area_id_fkey FOREIGN KEY (area_id)\n",
    "                            REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)'''\n",
    "\n",
    "pgquery(conn, \"DROP TABLE businessstats\",msg=\"cleared old table\")\n",
    "pgquery(conn, businessstats_schema, msg=\"created businessstats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO businessstats(area_id,num_businesses,retail_trade,accommodation_and_food_services,health_care_and_social_assistance,\n",
    "education_and_training,arts_and_recreation_services) VALUES (%(area_id)s, %(num_businesses)s, %(retail_trade)s,\n",
    "%(accommodation_and_food_services)s,%(health_care_and_social_assistance)s, %(education_and_training)s, \n",
    "%(arts_and_recreation_services)s)\"\"\"\n",
    "for row in data_businessstats:\n",
    "    #use average value to handle null\n",
    "    if row['num_businesses']=='':row['num_businesses']=business_mean['num_businesses']\n",
    "    if row['retail_trade']=='':row['retail_trade']=business_mean['retail_trade']\n",
    "    if row['accommodation_and_food_services']=='':row['accommodation_and_food_services']=business_mean['accommodation_and_food_services']\n",
    "    if row['health_care_and_social_assistance']=='':row['health_care_and_social_assistance']=business_mean['health_care_and_social_assistance']\n",
    "    if row['education_and_training'] == '': row['education_and_training']=business_mean['education_and_training']\n",
    "    if row['arts_and_recreation_services']=='':row['arts_and_recreation_services']=business_mean['arts_and_recreation_services']\n",
    "for row in data_businessstats:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censusstats_schema=''' CREATE TABLE IF NOT EXISTS censusstats(\n",
    "                                area_id integer NOT NULL,\n",
    "                                median_annual_household_income integer,\n",
    "                                avg_monthly_rent integer,\n",
    "                                CONSTRAINT censusstats_pkey PRIMARY KEY (area_id),\n",
    "                                CONSTRAINT censusstats_area_id_fkey FOREIGN KEY (area_id)\n",
    "                                REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)'''\n",
    "\n",
    "pgquery(conn, \"DROP TABLE censusstats\",msg=\"cleared old table\")\n",
    "pgquery(conn, censusstats_schema, msg=\"created censusstats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO censusstats(area_id,median_annual_household_income,avg_monthly_rent) VALUES (%(area_id)s, %(median_annual_household_income)s, %(avg_monthly_rent)s)\"\"\"\n",
    "for row in data_censusstats:\n",
    "    if row['median_annual_household_income']=='':row['median_annual_household_income']=censuss_mean['median_annual_household_income']\n",
    "    if row['avg_monthly_rent']=='':row['avg_monthly_rent']=censuss_mean['avg_monthly_rent']\n",
    "for row in data_censusstats:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_schema=''' CREATE TABLE IF NOT EXISTS neighbourhoods(\n",
    "                                area_id integer NOT NULL,\n",
    "                                area_name character varying(80),\n",
    "                                land_area double precision,\n",
    "                                population integer,\n",
    "                                number_of_dwellings integer,\n",
    "                                number_of_businesses integer,\n",
    "                                CONSTRAINT neighbourhoods_pkey PRIMARY KEY (area_id),\n",
    "                                CONSTRAINT neighbourhoods_area_id_fkey FOREIGN KEY (area_id)\n",
    "                                REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)'''\n",
    "\n",
    "pgquery(conn, \"DROP TABLE neighbourhoods\",msg=\"cleared old table\")\n",
    "pgquery(conn, neighbourhoods_schema, msg=\"created neighbourhoods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO neighbourhoods(area_id,area_name,land_area,population,number_of_dwellings,number_of_businesses) \n",
    "                VALUES (%(area_id)s, %(area_name)s, %(land_area)s,%(population)s,%(number_of_dwellings)s,%(number_of_businesses)s)\"\"\"\n",
    "for row in data_neighbourhoods:\n",
    "    for i in row:\n",
    "        if row[i]=='':row[i]=neighbourhoods_mean[i]\n",
    "for row in data_neighbourhoods:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikesharingpods_schema='''CREATE TABLE public.bikesharingpods(\n",
    "                          station_id integer NOT NULL,\n",
    "                          name varchar(80) ,\n",
    "                          num_bikes integer,\n",
    "                          num_scooters integer,\n",
    "                          geom GEOMETRY(Point,4326),\n",
    "                          description text COLLATE pg_catalog.\"default\",\n",
    "                          CONSTRAINT bikesharingpods_pkey PRIMARY KEY (station_id))'''\n",
    "pgquery(conn, \"DROP TABLE bikesharingpods\",msg=\"cleared old table\")\n",
    "pgquery(conn, bikesharingpods_schema, msg=\"created bikesharingpods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO bikesharingpods(station_id ,name,num_bikes,num_scooters,geom,description) \n",
    "                VALUES (%(station_id)s, %(name)s, %(num_bikes)s,%(num_scooters)s,ST_GEOMFROMTEXT(%(geom)s, 4326) ,%(description)s)\"\"\"\n",
    "for row in data_bikesharingpods:\n",
    "    row['geom']='Point('+row['longitude']+' '+row['latitude']+')'\n",
    "for row in data_bikesharingpods:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import extra dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "crimefeatures = gpd.read_file('data/crimefeatures.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimefeatures_schema = '''CREATE TABLE CRIMEFEATURES (\n",
    "                     count INTEGER, \n",
    "                     pop INTEGER, \n",
    "                     name VARCHAR(80), \n",
    "                     RegionId INTEGER,\n",
    "                     geom GEOMETRY(MULTIPOLYGON,4326),\n",
    "                     CONSTRAINT crimefeatures_pkey PRIMARY KEY (regionid))'''\n",
    "pgquery(conn, \"DROP TABLE crimefeatures\",msg=\"cleared old table\")\n",
    "pgquery(conn, crimefeatures_schema, msg=\"created crimefeatures table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO CRIMEFEATURES(count,pop,name,regionid,geom) VALUES (%(count)s, %(pop)s, %(name)s,%(regionid)s,ST_GEOMFROMTEXT(%(geom)s, 4326))\"\"\"\n",
    "values={}\n",
    "for row in crimefeatures.values:\n",
    "    values['count']=row[0]\n",
    "    values['pop']=row[1]\n",
    "    values['name']=row[2]\n",
    "    values['regionid']=row[3]\n",
    "    values['geom']=str(row[4])\n",
    "    pgquery(conn, insert_stmt, values, \"row inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the numbers crimes for areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data and the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All areas that have corresponding crime count are included in the trainging set. Also, 4 attributes are selected for the learning, which are the population, the number of businesses, the median annual household income and average monthly rent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = pgconnect()\n",
    "\n",
    "# Query the training data\n",
    "query = '''SELECT N.area_id, N.population, N.number_of_businesses, median_annual_household_income AS income, avg_monthly_rent AS rent, CF.count\n",
    "             FROM Neighbourhoods N JOIN CensusStats CS USING (area_id)\n",
    "                                   JOIN CrimeFeatures CF ON (LOWER(N.area_name) = LOWER(CF.name));'''\n",
    "\n",
    "training_data = pgquery(conn, query)\n",
    "print(len(training_data))\n",
    "print(training_data)\n",
    "\n",
    "# Query the testing data\n",
    "query = '''SELECT N.area_id, N.population, N.number_of_businesses, median_annual_household_income AS income, avg_monthly_rent AS rent\n",
    "             FROM Neighbourhoods N JOIN CensusStats USING (area_id)\n",
    "            WHERE LOWER(N.area_name) NOT IN (SELECT LOWER(name) FROM CrimeFeatures);'''\n",
    "\n",
    "testing_data = pgquery(conn, query)\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree regression model is built based on the training set. Then the model makes predicitons for each entry in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Exact attributes and targets for all data\n",
    "training_attrs = []\n",
    "training_targets = []\n",
    "\n",
    "for entry in training_data:\n",
    "    training_attrs.append(entry[1:-1])\n",
    "    training_targets.append(entry[-1])\n",
    "\n",
    "# Build a decision tree regressor\n",
    "regr = DecisionTreeRegressor()\n",
    "regr.fit(training_attrs, training_targets)\n",
    "\n",
    "# Exact attributes of each testing entry\n",
    "testing_attrs = []\n",
    "\n",
    "for entry in testing_data:\n",
    "    testing_attrs.append(entry[1:])\n",
    "    \n",
    "# Make predictions\n",
    "predictions = regr.predict(testing_attrs)\n",
    "\n",
    "# Put the predictions back to the testing data\n",
    "result = []\n",
    "for i in range(len(testing_data)):\n",
    "    \n",
    "    entry = []\n",
    "    \n",
    "    # TODO: Only the first element is needed.\n",
    "    for elem in testing_data[i]:\n",
    "        entry.append(elem)\n",
    "    \n",
    "    entry.append(predictions[i]);\n",
    "    \n",
    "    result.append(entry)\n",
    "\n",
    "# Print the result\n",
    "for entry in result:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the training data and the testing data together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all data are put together in one list, which is ready for the calulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in training_data:\n",
    "    if entry[0] >= 99999999:\n",
    "        result.append(entry)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the result into postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedresult_schema=''' CREATE TABLE IF NOT EXISTS predictedresult(\n",
    "                                area_id integer NOT NULL,\n",
    "                                population integer,\n",
    "                                crime_count integer,\n",
    "                                CONSTRAINT predictedresult_pkey PRIMARY KEY (area_id),\n",
    "                                CONSTRAINT predictedresult_area_id_fkey FOREIGN KEY (area_id)\n",
    "                                REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)\n",
    "                                '''\n",
    "\n",
    "pgquery(conn, \"DROP TABLE predictedresult\",msg=\"cleared old table\")\n",
    "pgquery(conn, predictedresult_schema, msg=\"created predictedresult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO predictedresult(area_id,population,crime_count) VALUES (%(area_id)s, %(population)s, %(crime_count)s)\"\"\"\n",
    "values={}\n",
    "for row in result:\n",
    "    values['area_id']=row[0]\n",
    "    values['population']=row[1]\n",
    "    values['crime_count']=row[5]\n",
    "    pgquery(conn, insert_stmt, values, \"row inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cyclability-score as given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "podsquery='''select area_id,count(station_id),land_area,count(station_id)/land_area as bikepod_density\n",
    "from neighbourhoods n left outer join \n",
    "(select *\n",
    "from bikesharingpods b , aust au\n",
    "where st_contains(au.geom,b.geom))\n",
    "as pods\n",
    "on (pods.sa2_main16=n.area_id)\n",
    "group by area_id\n",
    "order by area_id'''\n",
    "podsresponse=pgquery( conn, podsquery)\n",
    "podsmeasures=[]\n",
    "for row in podsresponse:\n",
    "    podsmeasures+=[row[3]]\n",
    "podsmean=np.mean(podsmeasures)\n",
    "podsstd=np.std(podsmeasures)\n",
    "zbikepods=[]\n",
    "for row in podsresponse:\n",
    "    newdic={}\n",
    "    newdic['area_id']=row[0]\n",
    "    newdic['z_bikepods_density']=(row[3]-podsmean)/podsstd\n",
    "    zbikepods+=[newdic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zbikepods_schema=''' CREATE TABLE IF NOT EXISTS zbikepods(\n",
    "                        area_id integer NOT NULL,\n",
    "                        z_bikepods_density float,\n",
    "                        CONSTRAINT zbikepods_pkey PRIMARY KEY (area_id),\n",
    "                        CONSTRAINT zbikepods_area_id_fkey FOREIGN KEY (area_id)\n",
    "                        REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)'''\n",
    "pgquery(conn, \"DROP TABLE zbikepods\",msg=\"cleared old table\")\n",
    "pgquery(conn, zbikepods_schema, msg=\"created zbikepods table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO zbikepods(area_id,z_bikepods_density) VALUES (%(area_id)s, %(z_bikepods_density)s)\"\"\"\n",
    "for row in zbikepods:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populationquery='''select area_id,(population/land_area-avg)/sd as z_population_density from neighbourhoods N \n",
    ",(select avg(population/land_area) as \"avg\",stddev(population/land_area) as sd from neighbourhoods) as st\n",
    "'''\n",
    "populationresponse=pgquery( conn, populationquery)\n",
    "zpopulation=[]\n",
    "for row in populationresponse:\n",
    "    newdic={}\n",
    "    newdic['area_id']=row[0]\n",
    "    newdic['z_population_density']=row[1]\n",
    "    zpopulation+=[newdic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zpopulation_schema=''' CREATE TABLE IF NOT EXISTS zpopulation(\n",
    "                        area_id integer NOT NULL,\n",
    "                        z_population_density float,\n",
    "                        CONSTRAINT zpopulation_pkey PRIMARY KEY (area_id),\n",
    "                        CONSTRAINT zpopulation_area_id_fkey FOREIGN KEY (area_id)\n",
    "                        REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)'''\n",
    "pgquery(conn, \"DROP TABLE zpopulation\",msg=\"cleared old table\")\n",
    "pgquery(conn, zpopulation_schema, msg=\"created zpopulation table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO zpopulation(area_id,z_population_density) VALUES (%(area_id)s, %(z_population_density)s)\"\"\"\n",
    "for row in zpopulation:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwellingquery='''select area_id,(number_of_dwellings/land_area-avg)/sd as z_number_of_dwellings_density \n",
    "from neighbourhoods N ,\n",
    "(select avg(number_of_dwellings/land_area) as \"avg\",stddev(number_of_dwellings/land_area) as sd \n",
    " from neighbourhoods) as st'''\n",
    "dwellingresponse=pgquery( conn, dwellingquery)\n",
    "zdwelling=[]\n",
    "for row in dwellingresponse:\n",
    "    newdic={}\n",
    "    newdic['area_id']=row[0]\n",
    "    newdic['z_dwelling_density']=row[1]\n",
    "    zdwelling+=[newdic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdwelling_schema=''' CREATE TABLE IF NOT EXISTS zdwelling(\n",
    "                        area_id integer NOT NULL,\n",
    "                        z_dwelling_density float,\n",
    "                        CONSTRAINT zdwelling_pkey PRIMARY KEY (area_id),\n",
    "                        CONSTRAINT zdwelling_area_id_fkey FOREIGN KEY (area_id)\n",
    "                        REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)'''\n",
    "pgquery(conn, \"DROP TABLE zdwelling\",msg=\"cleared old table\")\n",
    "pgquery(conn, zdwelling_schema, msg=\"created zdwelling table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO zdwelling(area_id,z_dwelling_density) VALUES (%(area_id)s, %(z_dwelling_density)s)\"\"\"\n",
    "for row in zdwelling:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servicequery='''select area_id,(measure-avg)/stddev\n",
    "from(\n",
    "select avg(measure),stddev(measure)\n",
    "from\n",
    "(select area_id,num_businesses*a/sum+retail_trade*b/sum+accommodation_and_food_services*c/sum+health_care_and_social_assistance*d/sum+\n",
    "education_and_training*e/sum+arts_and_recreation_services*f/sum as measure\n",
    "from businessstats,\n",
    "(select avg(num_businesses) as a,avg(retail_trade) as b,avg(accommodation_and_food_services\n",
    ") as c,avg(health_care_and_social_assistance\n",
    ") as d,avg(education_and_training\n",
    ") as e,avg(arts_and_recreation_services\n",
    ") as f,avg(num_businesses)+avg(retail_trade)+avg(accommodation_and_food_services\n",
    ")+avg(health_care_and_social_assistance\n",
    ")+avg(education_and_training\n",
    ")+avg(arts_and_recreation_services\n",
    ") as sum  from businessstats) as st)\n",
    "as mea\n",
    ") as std,\n",
    "(select area_id,num_businesses*a/sum+retail_trade*b/sum+accommodation_and_food_services*c/sum+health_care_and_social_assistance*d/sum+\n",
    "education_and_training*e/sum+arts_and_recreation_services*f/sum as measure\n",
    "from businessstats,\n",
    "(select avg(num_businesses) as a,avg(retail_trade) as b,avg(accommodation_and_food_services\n",
    ") as c,avg(health_care_and_social_assistance\n",
    ") as d,avg(education_and_training\n",
    ") as e,avg(arts_and_recreation_services\n",
    ") as f,avg(num_businesses)+avg(retail_trade)+avg(accommodation_and_food_services\n",
    ")+avg(health_care_and_social_assistance\n",
    ")+avg(education_and_training\n",
    ")+avg(arts_and_recreation_services\n",
    ") as sum  from businessstats) as st)\n",
    "as mea'''\n",
    "serviceresponse=pgquery( conn, servicequery)\n",
    "zservice=[]\n",
    "for row in serviceresponse:\n",
    "    newdic={}\n",
    "    newdic['area_id']=row[0]\n",
    "    newdic['z_service_balance']=row[1]\n",
    "    zservice+=[newdic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zservice_schema=''' CREATE TABLE IF NOT EXISTS zservice(\n",
    "                        area_id integer NOT NULL,\n",
    "                        z_service_balance float,\n",
    "                        CONSTRAINT zservice_pkey PRIMARY KEY (area_id),\n",
    "                        CONSTRAINT zservice_area_id_fkey FOREIGN KEY (area_id)\n",
    "                        REFERENCES public.statisticalareas (area_id) MATCH SIMPLE)'''\n",
    "pgquery(conn, \"DROP TABLE zservice\",msg=\"cleared old table\")\n",
    "pgquery(conn, zservice_schema, msg=\"created zservice table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_stmt = \"\"\"INSERT INTO zservice(area_id,z_service_balance) VALUES (%(area_id)s, %(z_service_balance)s)\"\"\"\n",
    "for row in zservice:\n",
    "    pgquery(conn, insert_stmt, row, \"row inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Cyclability Score and the Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pgconnect()\n",
    "\n",
    "query = '''SELECT N.area_id,\n",
    "                  N.area_name,\n",
    "                  median_annual_household_income AS income,\n",
    "                  avg_monthly_rent AS rent,\n",
    "                  z_bikepods_density + z_population_density + z_dwelling_density + z_service_balance + z_crime AS score\n",
    "             FROM Neighbourhoods N JOIN CensusStats USING (area_id)\n",
    "                                   JOIN ZBikePods   USING (area_id)\n",
    "                                   JOIN ZPopulation USING (area_id)\n",
    "                                   JOIN ZDwelling   USING (area_id)\n",
    "                                   JOIN ZService    USING (area_id)\n",
    "                                   JOIN ZCrime      USING (area_id);'''\n",
    "\n",
    "res = pgquery(conn, query)\n",
    "\n",
    "query = '''SELECT MAX(z_bikepods_density + z_population_density + z_dwelling_density + z_service_balance + z_crime),\n",
    "                  MIN(z_bikepods_density + z_population_density + z_dwelling_density + z_service_balance + z_crime)\n",
    "             FROM Neighbourhoods N JOIN ZBikePods   USING (area_id)\n",
    "                                   JOIN ZPopulation USING (area_id)\n",
    "                                   JOIN ZDwelling   USING (area_id)\n",
    "                                   JOIN ZService    USING (area_id)\n",
    "                                   JOIN ZCrime      USING (area_id);'''\n",
    "\n",
    "max_score, min_score = pgquery(conn, query)[0]\n",
    "\n",
    "data = []\n",
    "\n",
    "for row in res:\n",
    "    \n",
    "    entry = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        entry.append(row[i])\n",
    "        \n",
    "    entry.append((row[-1] - min_score) / (max_score - min_score) * 100)\n",
    "    \n",
    "    data.append(entry)\n",
    "\n",
    "scores = [entry[-1] for entry in data]\n",
    "income = [entry[2] for entry in data]\n",
    "rent = [entry[3] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bp_dict = plt.boxplot(scores, labels=['cyclability score'], vert=False, showmeans=True)\n",
    "\n",
    "for line in bp_dict['medians']:\n",
    "    x, y = line.get_xydata()[1]\n",
    "    plt.text(x, y, '%.1f' % x, horizontalalignment='center')\n",
    "\n",
    "for line in bp_dict['boxes']:\n",
    "    x, y = line.get_xydata()[0]\n",
    "    plt.text(x,y, '%.1f' % x, horizontalalignment='center', verticalalignment='top')\n",
    "    x, y = line.get_xydata()[3]\n",
    "    plt.text(x,y, '%.1f' % x, horizontalalignment='center', verticalalignment='top')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coef = np.corrcoef([income, rent, scores])\n",
    "print(corr_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According the output of the `corrcoef` funciton, the correlation coefficient of income and scores is $0.24127378$ and the correlation coefficient of rent and scores is $0.40395861$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, y, x_label=None, y_label=None, title=None):\n",
    "    \n",
    "    plt.scatter(x, y, s=7.0, c='#EB522C')\n",
    "\n",
    "    axes = plt.gca()\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    x_plot = np.linspace(axes.get_xlim()[0], axes.get_xlim()[1], 100)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.plot(x_plot, a * x_plot + b, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income - Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(income, scores, 'median annual household income', 'cyclability score', 'median annual household income - cyclability score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rent - Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(rent, scores, 'average monthly rent', 'cyclability score', 'average monthly rent - cyclability score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(corr_coef)\n",
    "plt.colorbar()\n",
    "plt.summer()\n",
    "plt.xticks(np.arange(3), ('Income', 'Rent', 'Score'))\n",
    "plt.yticks(np.arange(3), ('Income', 'Rent', 'Score'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
